# -*- coding: utf-8 -*-
"""SQL Injection Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ts8DsnfFNEMDmCsQuuOJm_we_Uw9JPLl

Dataset Reference: https://www.kaggle.com/syedsaqlainhussain/sql-injection-dataset
"""

# Mounting google colab
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
import pandas as pd

PATH_TO_DATASET = '/content/gdrive/MyDrive/Datasets/Security/sqli.csv'
dataset = pd.read_csv(PATH_TO_DATASET, encoding='utf-16')

# Converting the words to vectors
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(stop_words=stopwords.words('english'))
queries = vectorizer.fit_transform(dataset['Sentence'].values.astype('U')).toarray()

# Train and Test Split
from sklearn.model_selection import train_test_split
Y = dataset.Label
X = queries
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)

# Training the classifier
from sklearn.linear_model import LogisticRegression
model = LogisticRegression().fit(X_train, Y_train)

# Testing the accuracy
from sklearn.metrics import accuracy_score
Y_pred = model.predict(X_test)
accuracy_score(Y_test, Y_pred)

# Saving the model
import pickle
import os
save_location = '/content/gdrive/MyDrive/Models/Security Models'
model_name = 'sql_inject_model.sav'
save_model = {
    'model': model,
    'vectorizer': vectorizer
}
pickle.dump(save_model, open(os.path.join(save_location, model_name), 'wb'))

# Fetching the model
import pickle
import os
save_location = '/content/gdrive/MyDrive/Models/Security Models'
model_name = 'sql_inject_model.sav'
fetch_model = pickle.load(open(os.path.join(save_location, model_name), 'rb'))
model = fetch_model['model']
vectorizer = fetch_model['vectorizer']

test_corpus = [
  'http://localhost:500/sql-inject?q=select * from emp where 1 = 1',
  # 'http://localhost:500/sql-inject?q=1001'
]
test_query = vectorizer.transform(test_corpus).toarray()

test_prediction = model.predict(test_query)

int(test_prediction[0])

